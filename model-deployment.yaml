apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "rf-model-deployment"
spec:
  predictor:
      containers:
      - name: "rf-model"
        image: "rhiiitech/random_forest_fromcode:latest"
        ports:
        - containerPort: 8080
          protocol: TCP
        - containerPort: 8082
          protocol: TCP
        env:
        - name: PROTOCOL
          value: "v2"
